{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f79e372-818f-40a1-8308-c6eb904581b5",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3c5670-df9d-4c58-91ee-78190d373daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import amcatclient\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836806f4-4bc1-487d-ad41-cda8453011ae",
   "metadata": {},
   "source": [
    "## 1. Download data (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be3fb8-1e0d-4bee-9f25-21b57188106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    conn = amcatclient.AmcatAPI(\"https://vu.amcat.nl\")\n",
    "    docs = conn.get_articles(project=69, articleset=3521, start_date=\"2021-01-01\", columns=[\"id\", \"title\", \"date\", \"url\", \"publisher\", \"text\"])\n",
    "    data = []\n",
    "    for doc in docs:\n",
    "        data.append(doc)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f7103a-bbf7-4068-8766-e2227bfb13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data_csv(data, file_name):\n",
    "    pd.DataFrame(data).to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b01a2-f085-4a71-9c94-278ae767bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data_doccano(data, file_name):\n",
    "    out_file = open(file_name, \"w\")\n",
    "    for d in data:\n",
    "        print(json.dumps(d), file=out_file)\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b7941-fed3-41e0-9ead-eba97789b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c5c643-8c27-498e-b9a3-0f8a42e335d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_csv(data, \"../data/teletekst.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861ff24-4e0b-4775-a2a8-4dde168afe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_doccano(data, \"../data/teletekst.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9faa3a-94c7-4656-ba0c-598f03ab057a",
   "metadata": {},
   "source": [
    "## 2. Extract entities from data\n",
    "\n",
    "Documentation for VU linguistic processing docker: https://vu-rm-pip3.readthedocs.io/en/latest/docker.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c97a7e6-7108-404e-b202-b747d93868c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "import os\n",
    "import tempfile\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854c2485-d1da-49d4-a585-389c366b2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    return pd.read_csv(file_name).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e59b7762-8bee-479c-9ad6-3d567a46881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_text_in_file(text):\n",
    "    _, tmp_file_name_with_dir = tempfile.mkstemp(dir=\"tmp\")\n",
    "    tmp_file = open(tmp_file_name_with_dir, \"w\")\n",
    "    print(text, file=tmp_file)\n",
    "    tmp_file.close()\n",
    "    return tmp_file_name_with_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80cbe963-3673-468e-85ac-b8eb1ac96449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_process(tmp_file_name_with_dir):\n",
    "    tmp_file_name_without_dir = tmp_file_name_with_dir.split(\"/\")[-1]\n",
    "    os.system(f\"docker run -v $(pwd)/tmp/:/wrk/ vucltl/vu-rm-pip3 -m entities /wrk/{tmp_file_name_without_dir} > {tmp_file_name_with_dir}.out 2> {tmp_file_name_with_dir}.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ceb9f42-c166-4f2a-bffb-a3374c5f3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations(tmp_file_name_with_dir):\n",
    "    processed_file = open(f\"{tmp_file_name_with_dir}.out\", \"r\")\n",
    "    processed_data = \"\"\n",
    "    for line in processed_file:\n",
    "        processed_data += line\n",
    "    processed_file.close()\n",
    "    return BeautifulSoup(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de7c58c0-b98c-40b1-b6a7-764c95b19391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_files(tmp_file_name_with_dir):\n",
    "    os.unlink(tmp_file_name_with_dir)\n",
    "    os.unlink(f\"{tmp_file_name_with_dir}.out\")\n",
    "    os.unlink(f\"{tmp_file_name_with_dir}.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c9b336-49d2-48aa-ad5a-8986b0a088df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_text(text):\n",
    "    tmp_file_name_with_dir = store_text_in_file(text)\n",
    "    annotate_process(tmp_file_name_with_dir)\n",
    "    annotation_soup = read_annotations(tmp_file_name_with_dir)\n",
    "    cleanup_files(tmp_file_name_with_dir)\n",
    "    return annotation_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd699f32-3f41-4937-962b-60c350a181a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(soup):\n",
    "    words = {}\n",
    "    for word in soup.find_all(\"wf\"):\n",
    "        if word[\"id\"] not in words:\n",
    "            words[word[\"id\"]] = [ word.text ] \n",
    "        else:\n",
    "            words[word[\"id\"]].append(word.text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6a96ae-c8e1-4745-929c-ff73d59f06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms(soup):\n",
    "    terms = {}\n",
    "    for term in soup.find_all(\"term\"):\n",
    "        for target in term.find_all(\"target\"):\n",
    "            if term[\"id\"] not in terms:\n",
    "                terms[term[\"id\"]] = [ target[\"id\"] ]\n",
    "            else:\n",
    "                terms[term[\"id\"]].append(target[\"id\"])\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878c22b9-a56a-463a-ba6e-66f62e321279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(soup):\n",
    "    entities = {}\n",
    "    for entity in soup.find_all(\"entity\"):\n",
    "        for target in entity.find_all(\"target\"):\n",
    "            if entity[\"id\"] not in entities:\n",
    "                entities[entity[\"id\"]] = { \"type\": entity[\"type\"], \"targets\": [ target[\"id\"] ] }\n",
    "            else:\n",
    "                entities[entity[\"id\"]][\"targets\"].append(target[\"id\"])\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15819ca1-d785-4f00-a318-0122dd3e9789",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(\"../data/teletekst.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a48e1e3-dae3-4324-8c0b-d71d3eafa38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = annotate_text(data[2][\"text\"])\n",
    "words = get_words(soup)\n",
    "terms = get_terms(soup)\n",
    "entities = get_entities(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e02b01b-f569-4f3e-ad8b-e5442be55d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Het dodental van het ongeluk met een kabelbaan in Noord-Italië is opgelopen naar veertien. Vanavond overleed in een ziekenhuis in Turijn een van de twee zwaargewonde kinderen die uit de neergestorte gondel waren gehaald.\\n\\nEen cabine van de kabelbaan van Stresa aan het Lago Maggiore naar de top van de Monte Mottarone stortte in de diepte toen een kabel het begaf. In de cabine werden daarna negen lichamen gevonden, en in het bos op de berg nog eens vier.\\n\\nDe kabelbaan was pas weer open, na een versoepeling van de coronamaatregelen. Het laatste grote onderhoud was tussen 2014 en 2016 uitgevoerd.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad8b6d77-8a86-4e5c-8a2f-6ab27dfd08b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC Noord-Italië \n",
      "LOC Turijn \n",
      "LOC Stresa \n",
      "ORG Lago Maggiore \n",
      "ORG Monte Mottarone \n"
     ]
    }
   ],
   "source": [
    "for entity in entities:\n",
    "    print(entities[entity][\"type\"], end=\" \")\n",
    "    for target in entities[entity][\"targets\"]:\n",
    "        for term in terms[target]:\n",
    "            for word in words[term]:\n",
    "                print(word, end=\" \")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72eb8ea-1358-4cf2-91e7-b31e55212489",
   "metadata": {},
   "source": [
    "## 3. e2e\n",
    "\n",
    "Instructions: https://github.com/Filter-Bubble/e2e-Dutch\n",
    "\n",
    "First download stanza nl with: `stanza.download('nl')`\n",
    "\n",
    "The command `stanza.Pipeline` reports that a model is missing. It can be downloaded with `git clone https://huggingface.co/GroNLP/bert-base-dutch-cased` but it is unclear how to proceed next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdffeba5-5fbf-4ff1-ac9e-913b64faaeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 17:32:41 INFO: Loading these models for language: nl (Dutch):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | alpino  |\n",
      "| coref     | default |\n",
      "=======================\n",
      "\n",
      "2021-07-06 17:32:41 INFO: Use device: cpu\n",
      "2021-07-06 17:32:41 INFO: Loading: tokenize\n",
      "2021-07-06 17:32:41 INFO: Loading: coref\n",
      "Setting CUDA_VISIBLE_DEVICES to: \n",
      "Running model: final\n",
      "Loading context embeddings..\n",
      "Loading head embeddings..\n",
      "Loading BERT model...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to load weights from pytorch checkpoint file for 'wietsedv/bert-base-dutch-cased' at '/home/erikt/.cache/torch/transformers/7a7191f5270caad7138d7e61b6e7a8e9d0eaad0d058a9faabb3896b520de8e9a.ead4c92543de4acacd907c329709df627a019151e95d79ced000d1199473fd29'If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at /pytorch/caffe2/serialize/inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at /pytorch/caffe2/serialize/inline_container.cc:132)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f54aa6c8193 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages/torch/lib/libc10.so)\nframe #1: caffe2::serialize::PyTorchStreamReader::init() + 0x1f5b (0x7f54ad8509eb in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #2: caffe2::serialize::PyTorchStreamReader::PyTorchStreamReader(std::string const&) + 0x64 (0x7f54ad851c04 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #3: <unknown function> + 0x6c6536 (0x7f54f5782536 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #4: <unknown function> + 0x295a74 (0x7f54f5351a74 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #5: _PyMethodDef_RawFastCallDict + 0x267 (0x55eca6b16da7 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #6: _PyCFunction_FastCallDict + 0x21 (0x55eca6b16f01 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #7: _PyObject_Call_Prepend + 0x63 (0x55eca6b14e23 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #8: PyObject_Call + 0x6e (0x55eca6b0751e in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #9: <unknown function> + 0x9eed7 (0x55eca6a7ced7 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #10: _PyObject_FastCallKeywords + 0x128 (0x55eca6b4ee98 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #11: _PyEval_EvalFrameDefault + 0x53ae (0x55eca6bb449e in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #12: _PyEval_EvalCodeWithName + 0x5da (0x55eca6af4c0a in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #13: _PyFunction_FastCallDict + 0x1d5 (0x55eca6af59f5 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #14: _PyObject_Call_Prepend + 0x63 (0x55eca6b14e23 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #15: <unknown function> + 0x17022a (0x55eca6b4e22a in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #16: _PyObject_FastCallKeywords + 0x128 (0x55eca6b4ee98 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #17: _PyEval_EvalFrameDefault + 0x4ac6 (0x55eca6bb3bb6 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #18: _PyEval_EvalCodeWithName + 0x2f9 (0x55eca6af4929 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #19: _PyFunction_FastCallKeywords + 0x387 (0x55eca6b45f87 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #20: _PyEval_EvalFrameDefault + 0x14dc (0x55eca6bb05cc in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #21: _PyEval_EvalCodeWithName + 0xba9 (0x55eca6af51d9 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #22: _PyFunction_FastCallKeywords + 0x387 (0x55eca6b45f87 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #23: _PyEval_EvalFrameDefault + 0x4b69 (0x55eca6bb3c59 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #24: _PyFunction_FastCallKeywords + 0xfb (0x55eca6b45cfb in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #25: _PyEval_EvalFrameDefault + 0x4b69 (0x55eca6bb3c59 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #26: _PyFunction_FastCallDict + 0x10b (0x55eca6af592b in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #27: _PyObject_Call_Prepend + 0x63 (0x55eca6b14e23 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #28: <unknown function> + 0x17022a (0x55eca6b4e22a in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #29: _PyObject_FastCallKeywords + 0x128 (0x55eca6b4ee98 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #30: _PyEval_EvalFrameDefault + 0x53ae (0x55eca6bb449e in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #31: _PyEval_EvalCodeWithName + 0x2f9 (0x55eca6af4929 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #32: _PyFunction_FastCallDict + 0x400 (0x55eca6af5c20 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #33: _PyObject_Call_Prepend + 0x63 (0x55eca6b14e23 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #34: <unknown function> + 0x17022a (0x55eca6b4e22a in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #35: _PyObject_FastCallKeywords + 0x128 (0x55eca6b4ee98 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #36: _PyEval_EvalFrameDefault + 0x5866 (0x55eca6bb4956 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #37: _PyEval_EvalCodeWithName + 0x2f9 (0x55eca6af4929 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #38: _PyFunction_FastCallDict + 0x400 (0x55eca6af5c20 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #39: _PyObject_Call_Prepend + 0x63 (0x55eca6b14e23 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #40: <unknown function> + 0x17022a (0x55eca6b4e22a in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #41: _PyObject_FastCallKeywords + 0x128 (0x55eca6b4ee98 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #42: _PyEval_EvalFrameDefault + 0x5866 (0x55eca6bb4956 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #43: _PyEval_EvalCodeWithName + 0x2f9 (0x55eca6af4929 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #44: _PyFunction_FastCallDict + 0x400 (0x55eca6af5c20 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #45: _PyObject_Call_Prepend + 0x63 (0x55eca6b14e23 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #46: <unknown function> + 0x17022a (0x55eca6b4e22a in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #47: _PyObject_FastCallKeywords + 0x128 (0x55eca6b4ee98 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #48: _PyEval_EvalFrameDefault + 0x5866 (0x55eca6bb4956 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #49: _PyEval_EvalCodeWithName + 0x2f9 (0x55eca6af4929 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #50: PyEval_EvalCodeEx + 0x44 (0x55eca6af57e4 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #51: PyEval_EvalCode + 0x1c (0x55eca6af580c in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #52: <unknown function> + 0x1e0c70 (0x55eca6bbec70 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #53: _PyMethodDef_RawFastCallKeywords + 0xe9 (0x55eca6b465f9 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #54: _PyCFunction_FastCallKeywords + 0x21 (0x55eca6b46891 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x47d4 (0x55eca6bb38c4 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #56: _PyGen_Send + 0x2a2 (0x55eca6b4fea2 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #57: _PyEval_EvalFrameDefault + 0x1acc (0x55eca6bb0bbc in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #58: _PyGen_Send + 0x2a2 (0x55eca6b4fea2 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #59: _PyEval_EvalFrameDefault + 0x1acc (0x55eca6bb0bbc in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #60: _PyGen_Send + 0x2a2 (0x55eca6b4fea2 in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #61: _PyMethodDef_RawFastCallKeywords + 0x8c (0x55eca6b4659c in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #62: _PyMethodDescr_FastCallKeywords + 0x4f (0x55eca6b4ecdf in /home/erikt/anaconda3/envs/python37/bin/python)\nframe #63: _PyEval_EvalFrameDefault + 0x4cbc (0x55eca6bb3dac in /home/erikt/anaconda3/envs/python37/bin/python)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d16f8c13580c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0me2edutch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstanza\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tokenize,coref'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dit is een test document. Dit document bevat coreferenties.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang, dir, package, processors, logging_level, verbose, use_gpu, model_dir, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 self.processors[processor_name] = NAME_TO_PROCESSOR_CLASS[processor_name](config=curr_processor_config,\n\u001b[1;32m    137\u001b[0m                                                                                           \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                                                                                           use_gpu=self.use_gpu)\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mProcessorRequirementsException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;31m# if there was a requirements issue, add it to list which will be printed at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/e2edutch/stanza.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, pipeline, use_gpu)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Start and stop a session to cache all models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me2econfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/e2edutch/predict.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, config, verbose)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCorefModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/e2edutch/coref_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# load the model...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 self.bert_tokenizer, self.bert_model = bert.load_bert(\n\u001b[0;32m---> 73\u001b[0;31m                     self.config[\"lm_model_name\"])\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# ...and cache for next time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/e2edutch/bert.py\u001b[0m in \u001b[0;36mload_bert\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m         tokenizer = BertTokenizer.from_pretrained(\n\u001b[1;32m     13\u001b[0m             \"wietsedv/bert-base-dutch-cased\")\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wietsedv/bert-base-dutch-cased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bert-nl'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/bert-nl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 raise OSError(\n\u001b[0;32m--> 954\u001b[0;31m                     \u001b[0;34mf\"Unable to load weights from pytorch checkpoint file for '{pretrained_model_name_or_path}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m                     \u001b[0;34mf\"at '{resolved_archive_file}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m                     \u001b[0;34m\"If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to load weights from pytorch checkpoint file for 'wietsedv/bert-base-dutch-cased' at '/home/erikt/.cache/torch/transformers/7a7191f5270caad7138d7e61b6e7a8e9d0eaad0d058a9faabb3896b520de8e9a.ead4c92543de4acacd907c329709df627a019151e95d79ced000d1199473fd29'If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. "
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import e2edutch.stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang='nl', processors='tokenize,coref')\n",
    "\n",
    "doc = nlp('Dit is een test document. Dit document bevat coreferenties.')\n",
    "print ([[span.text for span in cluster] for cluster in doc.clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d892e98-7db6-4d23-bad8-d60b1d0ae2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
